{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "633328a7-f446-4062-8708-ee92534914a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, col, broadcast\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"broadcast_n_accumulators\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing data\n",
    "data = [\n",
    "    (1, 101, \"Apple\", 3, 2.5, \"2024-01-01\"),\n",
    "    (2, 102, \"Banana\", 5, 1.2, \"2024-01-02\"),\n",
    "    (3, 101, \"Orange\", 2, 3.0, \"2024-01-03\"),\n",
    "    (4, 103, \"Milk\", 1, 4.5, \"2024-01-04\"),\n",
    "    (5, 104, \"Eggs\", 12, 0.2, \"2024-01-05\"),\n",
    "    (6, 102, \"Bread\", 2, 2.0, \"2024-01-06\"),\n",
    "    (7, 105, \"Butter\", 1, 3.5, \"2024-01-07\"),\n",
    "    (8, 106, \"Cheese\", 1, 5.0, \"2024-01-08\"),\n",
    "    (9, 103, \"Cereal\", 2, 3.8, \"2024-01-09\"),\n",
    "    (10, 107, \"Juice\", 1, 2.5, \"2024-01-10\")\n",
    "]\n",
    "\n",
    "# customer dictionary\n",
    "customer_dict = {\n",
    "    101: \"John Doe\",\n",
    "    102: \"Jane Smith\",\n",
    "    103: \"Emily Davis\",\n",
    "    104: \"Michael Brown\",\n",
    "    105: \"Sarah Wilson\",\n",
    "    106: \"Chris Johnson\",\n",
    "    107: \"Laura Lee\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# broadcasting the customer dictionary\n",
    "Customers=spark.sparkContext.broadcast(customer_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCustomerName(cust_id):\n",
    "    return Customers.value[cust_id]\n",
    "getCustomerName_udf = udf(getCustomerName, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"TransactionID\", \"Customer\", \"Product\", \"Quantity\", \"Price\", \"TransactionDate\"]\n",
    "df = spark.createDataFrame(data, schema = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the dataset\n",
    "transformed_df = df.withColumn(\"Customer\", getCustomerName_udf(col(\"Customer\")))\n",
    "transformed_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting entire DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f67cbc5f-08ed-4aa3-a555-163803f1d3d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# preparing data\n",
    "data = [\n",
    "    (1, 101, \"Apple\", 3, 2.5, \"2024-01-01\"),\n",
    "    (2, 102, \"Banana\", 5, 1.2, \"2024-01-02\"),\n",
    "    (3, 101, \"Orange\", 2, 3.0, \"2024-01-03\"),\n",
    "    (4, 103, \"Milk\", 1, 4.5, \"2024-01-04\"),\n",
    "    (5, 104, \"Eggs\", 12, 0.2, \"2024-01-05\"),\n",
    "    (6, 102, \"Bread\", 2, 2.0, \"2024-01-06\"),\n",
    "    (7, 105, \"Butter\", 1, 3.5, \"2024-01-07\"),\n",
    "    (8, 106, \"Cheese\", 1, 5.0, \"2024-01-08\"),\n",
    "    (9, 103, \"Cereal\", 2, 3.8, \"2024-01-09\"),\n",
    "    (10, 107, \"Juice\", 1, 2.5, \"2024-01-10\")\n",
    "]\n",
    "\n",
    "# Define the customer data\n",
    "customer_data = [\n",
    "    (101, \"John Doe\", 28, \"New York\", \"johndoe@example.com\"),\n",
    "    (102, \"Jane Smith\", 34, \"Los Angeles\", \"janesmith@example.com\"),\n",
    "    (103, \"Emily Davis\", 23, \"Chicago\", \"emilydavis@example.com\"),\n",
    "    (104, \"Michael Brown\", 40, \"Houston\", \"michaelbrown@example.com\"),\n",
    "    (105, \"Sarah Wilson\", 30, \"San Francisco\", \"sarahwilson@example.com\"),\n",
    "    (106, \"Chris Johnson\", 36, \"Seattle\", \"chrisjohnson@example.com\"),\n",
    "    (107, \"Laura Lee\", 27, \"Austin\", \"lauralee@example.com\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_columns = [\"CustomerID\", \"Name\", \"Age\", \"City\", \"Email\"]\n",
    "columns = [\"TransactionID\", \"CustomerID\", \"Product\", \"Quantity\", \"Price\", \"TransactionDate\"]\n",
    "df = spark.createDataFrame(data, schema = columns)\n",
    "customer_df = spark.createDataFrame(customer_data, customer_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_broad = broadcast(customer_df)\n",
    "\n",
    "# transform the dataset\n",
    "transformed_df = df.join(cust_broad, df.CustomerID == cust_broad.CustomerID).selectExpr(\"TransactionID\", \"Product\", \"Quantity\", \"Price\", \"TransactionDate\", \"Name as CustomerName\", \"Age\", \"City\", \"Email\")\n",
    "transformed_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking explain plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "04653796-1aeb-4196-9e7b-e85325ff7f9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### With broadcating the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2256563c-9dd4-4de5-91ab-0379ff168569",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# transform the dataset\n",
    "transformed_df = df.join(cust_broad, df.CustomerID == cust_broad.CustomerID).selectExpr(\"TransactionID\", \"Product\", \"Quantity\", \"Price\", \"TransactionDate\", \"Name as CustomerName\", \"Age\", \"City\", \"Email\")\n",
    "transformed_df.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b4f48a28-e7bf-484f-aabb-0d214c486045",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Without broadcating the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0aec987-e513-4165-8e9b-397f4e5c2a1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# transform the dataset\n",
    "transformed_df = df.join(customer_df, df.CustomerID == customer_df.CustomerID).selectExpr(\"TransactionID\", \"Product\", \"Quantity\", \"Price\", \"TransactionDate\", \"Name as CustomerName\", \"Age\", \"City\", \"Email\")\n",
    "transformed_df.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accumulators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4c3d0ae-d959-4c5d-b09d-0e07b955d0c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create an accumulator for adding\n",
    "acc = spark.sparkContext.accumulator(0)\n",
    "\n",
    "acc.add(10)\n",
    "print(acc.value)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Broadcast & Accumulator — Shared Variables in Spark",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
