{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78c57d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7868b7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = r\"../../dataset/source_folder/csv/books.csv\"\n",
    "multi_csv_path = r\"../../dataset/source_folder/csv/\"\n",
    "parquet_path = r\"../../dataset/source_folder/parquet/books.parquet\"\n",
    "json_path = r\"../../dataset/source_folder/json/books.json\"\n",
    "json_multiline_path = r\"../../dataset/source_folder/json/books_multiline.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9eba1290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DhiVi:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>dataframe extraction</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1fcb22f4520>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"dataframe extraction\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36ebdaf",
   "metadata": {},
   "source": [
    "## Reading CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4befd0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------------------------+---------+---------+-------+------------+-------------+--------------+---------+\n",
      "|BOOK_ID|BOOK_TITLE                         |BOOK_COST|BOOK_TYPE|PUBL_ID|BOOK_EDITION|BOOK_DISCOUNT|ISBN          |PUBL_DATE|\n",
      "+-------+-----------------------------------+---------+---------+-------+------------+-------------+--------------+---------+\n",
      "|B0056  |DataBase Systems                   |935.27   |DB       |11     |Fifth       |10           |978-8131716250|01-May-08|\n",
      "|B0059  |Database Systems                   |1003.67  |DB       |11     |Eighth      |10           |978-8185015583|01-Jan-02|\n",
      "|B0063  |The Java TM Programming Language   |425      |PR       |11     |Third       |10           |978-8131702215|01-Jan-08|\n",
      "|B0067  |The Java TM EE5 Tutorial           |725      |PR       |11     |NULL        |18           |978-8131714928|03-Nov-06|\n",
      "|B0071  |The Complete Reference HTML & XHTML|540      |PR       |15     |Fourth      |16           |978-0070701946|08-Mar-10|\n",
      "+-------+-----------------------------------+---------+---------+-------+------------+-------------+--------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read\\\n",
    "    .format(\"csv\")\\\n",
    "    .option(\"schema\", \"book_id integer, book_title string, book_cost float, book_type string, publ_id integer, book_edition string, book_discount integer, isbn string, publ_date as string\")\\\n",
    "    .option(\"header\", True)\\\n",
    "    .option(\"sep\", \",\")\\\n",
    "    .option(\"inferSchema\", False)\\\n",
    "    .load(csv_path)\n",
    "df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131a9be7",
   "metadata": {},
   "source": [
    "## Reading Parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "576ce098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------------------------+---------+---------+-------+------------+-------------+--------------+---------+\n",
      "|BOOK_ID|BOOK_TITLE                         |BOOK_COST|BOOK_TYPE|PUBL_ID|BOOK_EDITION|BOOK_DISCOUNT|ISBN          |PUBL_DATE|\n",
      "+-------+-----------------------------------+---------+---------+-------+------------+-------------+--------------+---------+\n",
      "|B0056  |DataBase Systems                   |935.27   |DB       |11     |Fifth       |10           |978-8131716250|01-May-08|\n",
      "|B0059  |Database Systems                   |1003.67  |DB       |11     |Eighth      |10           |978-8185015583|01-Jan-02|\n",
      "|B0063  |The Java TM Programming Language   |425      |PR       |11     |Third       |10           |978-8131702215|01-Jan-08|\n",
      "|B0067  |The Java TM EE5 Tutorial           |725      |PR       |11     |NULL        |18           |978-8131714928|03-Nov-06|\n",
      "|B0071  |The Complete Reference HTML & XHTML|540      |PR       |15     |Fourth      |16           |978-0070701946|08-Mar-10|\n",
      "+-------+-----------------------------------+---------+---------+-------+------------+-------------+--------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read\\\n",
    "    .format(\"parquet\")\\\n",
    "    .option(\"header\", True)\\\n",
    "    .option(\"inferSchema\", True)\\\n",
    "    .load(parquet_path)\n",
    "df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645e674e",
   "metadata": {},
   "source": [
    "## Reading JSON file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1281a2ea",
   "metadata": {},
   "source": [
    "### Single line JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e7f333c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+------------+-------+----------------+---------+--------------+---------+-------+\n",
      "|BOOK_COST|BOOK_DISCOUNT|BOOK_EDITION|BOOK_ID|BOOK_TITLE      |BOOK_TYPE|ISBN          |PUBL_DATE|PUBL_ID|\n",
      "+---------+-------------+------------+-------+----------------+---------+--------------+---------+-------+\n",
      "|935.27   |10           |Fifth       |B0056  |DataBase Systems|DB       |978-8131716250|01-May-08|11     |\n",
      "+---------+-------------+------------+-------+----------------+---------+--------------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read multi line JSON file into dataframe\n",
    "df = spark.read \\\n",
    "    .format('org.apache.spark.sql.json') \\\n",
    "    .load(json_path)\n",
    "df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3a641d",
   "metadata": {},
   "source": [
    "### MultiLine JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24cc136e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+------------+-------+----------------+---------+--------------+---------+-------+\n",
      "|BOOK_COST|BOOK_DISCOUNT|BOOK_EDITION|BOOK_ID|BOOK_TITLE      |BOOK_TYPE|ISBN          |PUBL_DATE|PUBL_ID|\n",
      "+---------+-------------+------------+-------+----------------+---------+--------------+---------+-------+\n",
      "|935.27   |10           |Fifth       |B0056  |DataBase Systems|DB       |978-8131716250|01-May-08|11     |\n",
      "+---------+-------------+------------+-------+----------------+---------+--------------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read multi line JSON file into dataframe\n",
    "df = spark.read \\\n",
    "    .format('org.apache.spark.sql.json') \\\n",
    "    .option(\"multiline\", True) \\\n",
    "    .load(json_multiline_path)\n",
    "df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30aecf9e",
   "metadata": {},
   "source": [
    "## Reading Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5c450ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = spark.readStream\\\n",
    "#     .format('kafka')\\\n",
    "#     .option('kafka.bootstrap.servers', \"kafka_bootstrap_servers\")\\\n",
    "#     .option('subscribe', \"kafka_topic\")\\\n",
    "#     .option('startingoffsets', 'latest')\\\n",
    "#     .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da16cbf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+--------+------+\n",
      "|dept       |emp_id|emp_name|salary|\n",
      "+-----------+------+--------+------+\n",
      "|HR         |1     |Alice   |70000 |\n",
      "|Engineering|2     |Bob     |100000|\n",
      "|Engineering|3     |Charlie |95000 |\n",
      "|HR         |4     |Diana   |75000 |\n",
      "+-----------+------+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employee_file = \"../../dataset/source_folder/json/employees.json\"\n",
    "# Read multi line JSON file into dataframe\n",
    "employees = spark.read \\\n",
    "    .format('org.apache.spark.sql.json') \\\n",
    "    .option(\"multiline\", True) \\\n",
    "    .load(employee_file)\n",
    "employees.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6fee792d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+\n",
      "|       dept|department_count|\n",
      "+-----------+----------------+\n",
      "|Engineering|          195000|\n",
      "|         HR|          145000|\n",
      "+-----------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum, col\n",
    "employees.groupBy(\"dept\").agg(sum(col(\"salary\")).alias(\"department_count\")).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
